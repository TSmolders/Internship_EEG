{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AIM: extract statistical time-frequency features and store in dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[mean, std, median, skew, kurt] of power per channel per frequency band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import pickle\n",
    "import mne\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.time_frequency import tfr_multitaper\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# prevent extensive logging\n",
    "mne.set_log_level('WARNING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading in participants data\n",
    "and excluding replication data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all participants: (714, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participants_ID</th>\n",
       "      <th>DISC/REP</th>\n",
       "      <th>indication</th>\n",
       "      <th>formal_status</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>sessID</th>\n",
       "      <th>nrSessions</th>\n",
       "      <th>EC</th>\n",
       "      <th>EO</th>\n",
       "      <th>diagnosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>sub-88066909</td>\n",
       "      <td>DISCOVERY</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>ADHD_NF</td>\n",
       "      <td>36.04</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>sub-88025917</td>\n",
       "      <td>DISCOVERY</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>ADHD_NF</td>\n",
       "      <td>15.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ADHD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>sub-87967369</td>\n",
       "      <td>DISCOVERY</td>\n",
       "      <td>SMC</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>67.93</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>SMC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>sub-88066641</td>\n",
       "      <td>DISCOVERY</td>\n",
       "      <td>OCD</td>\n",
       "      <td>OCD</td>\n",
       "      <td>OCD</td>\n",
       "      <td>24.31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>OCD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>sub-88011833</td>\n",
       "      <td>DISCOVERY</td>\n",
       "      <td>MDD</td>\n",
       "      <td>MDD</td>\n",
       "      <td>MDD-rTMS</td>\n",
       "      <td>30.16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>MDD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     participants_ID   DISC/REP indication formal_status   Dataset    age  \\\n",
       "1186    sub-88066909  DISCOVERY       ADHD          ADHD   ADHD_NF  36.04   \n",
       "702     sub-88025917  DISCOVERY       ADHD          ADHD   ADHD_NF  15.00   \n",
       "161     sub-87967369  DISCOVERY        SMC       UNKNOWN       NaN  67.93   \n",
       "1182    sub-88066641  DISCOVERY        OCD           OCD       OCD  24.31   \n",
       "442     sub-88011833  DISCOVERY        MDD           MDD  MDD-rTMS  30.16   \n",
       "\n",
       "      gender  sessID  nrSessions    EC    EO diagnosis  \n",
       "1186       1       1           1  True  True      ADHD  \n",
       "702        1       1           1  True  True      ADHD  \n",
       "161        0       2           3  True  True       SMC  \n",
       "1182       0       1           1  True  True       OCD  \n",
       "442        0       1           1  True  True       MDD  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_participants = pd.read_pickle('D:\\Documents\\RU\\Master_Neurobiology\\Internship_jaar_2\\Project\\TD-BRAIN\\TDBRAIN_participants_V2_data\\df_participants.pkl')\n",
    "print(f'all participants: {df_participants.shape}')\n",
    "df_participants.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating montage and info object for PSD calculation with MNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Info | 8 non-empty values\n",
      " bads: []\n",
      " ch_names: Fp1, Fp2, F7, F3, Fz, F4, F8, FC3, FCz, FC4, T7, C3, Cz, C4, T8, ...\n",
      " chs: 26 EEG, 5 EOG, 1 ECG, 1 EMG\n",
      " custom_ref_applied: False\n",
      " dig: 29 items (3 Cardinal, 26 EEG)\n",
      " highpass: 0.0 Hz\n",
      " lowpass: 250.0 Hz\n",
      " meas_date: unspecified\n",
      " nchan: 33\n",
      " projs: []\n",
      " sfreq: 500.0 Hz\n",
      ">\n"
     ]
    }
   ],
   "source": [
    "## Set montage based on channel names and locations provided in Van Dijk et al., (2022) (Copied from Anne van Duijvenbode)\n",
    "\n",
    "ch_types = ['eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg',\\\n",
    "           'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', 'eeg', \\\n",
    "           'eog', 'eog', 'eog', 'eog', 'ecg', 'eog', 'emg']\n",
    "\n",
    "ch_names = ['Fp1', 'Fp2', 'F7', 'F3', 'Fz', 'F4', 'F8', 'FC3', 'FCz', 'FC4', 'T7', 'C3', 'Cz', 'C4', 'T8', 'CP3', \\\n",
    "            'CPz', 'CP4', 'P7', 'P3', 'Pz', 'P4', 'P8', 'O1', 'Oz', 'O2', 'VPVA', 'VNVB', 'HPHL', 'HNHR', 'Erbs', \\\n",
    "            'OrbOcc', 'Mass']\n",
    "\n",
    "dict_eeg_channels =  {ch_names[i]: ch_types[i] for i in range(len(ch_types))}\n",
    "\n",
    "dict_ch_pos = {'Fp1' : [-26.81, 84.06, -10.56],\n",
    "               'Fp2' : [29.41, 83.74, -10.04],\n",
    "               'F7'  : [-66.99, 41.69, -15.96],\n",
    "               'F3'  : [-48.05, 51.87, 39.87],\n",
    "               'Fz'  : [0.90, 57.01, 66.36],\n",
    "               'F4'  : [50.38, 51.84, 41.33],\n",
    "               'F8'  : [68.71, 41.16, -15.31],\n",
    "               'FC3' : [-58.83, 21.02, 54.82],\n",
    "               'FCz' : [0.57, 24.63, 87.63],\n",
    "               'FC4' : [60.29, 21.16, 55.58], \n",
    "               'T7'  : [-83.36, -16.52, -12.65], \n",
    "               'C3'  : [-65.57, -13.25, 64.98],\n",
    "               'Cz'  : [0.23, -11.28, 99.81],\n",
    "               'C4'  : [66.50, -12.80, 65.11],\n",
    "               'T8'  : [84.44, -16.65, -11.79], \n",
    "               'CP3' : [-65.51, -48.48, 68.57],\n",
    "               'CPz' : [-0.42, -48.77, 98.37], \n",
    "               'CP4' : [65.03, -48.35, 68.57], \n",
    "               'P7': [-71.46, -75.17, -3.70], \n",
    "               'P3'  : [-55.07, -80.11, 59.44], \n",
    "               'Pz'  : [-0.87, -82.23, 82.43],\n",
    "               'P4'  : [53.51, -80.13, 59.40], \n",
    "               'P8' : [71.10, -75.17, -3.69], \n",
    "               'O1'  : [-28.98, -114.52, 9.67],  \n",
    "               'Oz'  : [-1.41, -117.79, 15.84],\n",
    "               'O2'  : [26.89, -114.68, 9.45]\n",
    "              }\n",
    "\n",
    "dict_ch_pos_m = {'Fp1' : [-0.2681, 0.8406, -0.1056],\n",
    "               'Fp2' : [0.2941, 0.8374, -0.1004],\n",
    "               'F7'  : [-0.6699, 0.4169, -0.1596],\n",
    "               'F3'  : [-0.4805, 0.5187, 0.3987],\n",
    "               'Fz'  : [0.0090, 0.5701, 0.6636],\n",
    "               'F4'  : [0.5038, 0.5184, 0.4133],\n",
    "               'F8'  : [0.6871, 0.4116, -0.1531],\n",
    "               'FC3' : [-0.5883, 0.2102, 0.5482],\n",
    "               'FCz' : [0.0057, 0.2463, 0.8763],\n",
    "               'FC4' : [0.6029, 0.2116, 0.5558], \n",
    "               'T7'  : [-0.8336, -0.1652, -0.1265], \n",
    "               'C3'  : [-0.6557, -0.1325, 0.6498],\n",
    "               'Cz'  : [0.0023, -0.1128, 0.9981],\n",
    "               'C4'  : [0.6650, -0.1280, 0.6511],\n",
    "               'T8'  : [0.8444, -0.1665, -0.1179], \n",
    "               'CP3' : [-0.6551, -0.4848, 0.6857],\n",
    "               'CPz' : [-0.042, -0.4877, 0.9837], \n",
    "               'CP4' : [0.6503, -0.4835, 0.6857], \n",
    "               'P7'  : [-0.7146, -0.7517, -0.0370], \n",
    "               'P3'  : [-0.5507, -0.8011, 0.5944], \n",
    "               'Pz'  : [-0.0087, -0.8223, 0.8243],\n",
    "               'P4'  : [0.5351, -0.8013, 0.5940], \n",
    "               'P8'  : [0.7110, -0.7517, -0.0369], \n",
    "               'O1'  : [-0.2898, -1.1452, 0.0967],  \n",
    "               'Oz'  : [-0.0141, -1.1779, 0.1584],\n",
    "               'O2'  : [0.2689, -1.1468, 0.0945]\n",
    "              }\n",
    "\n",
    "dict_ch_pos_array = {'Fp1' : np.array([-0.02681, 0.08406, -0.01056]),\n",
    "               'Fp2' : np.array([0.02941, 0.08374, -0.01004]),\n",
    "               'F7'  : np.array([-0.06699, 0.04169, -0.01596]),\n",
    "               'F3'  : np.array([-0.04805, 0.05187, 0.03987]),\n",
    "               'Fz'  : np.array([0.00090, 0.05701, 0.06636]),\n",
    "               'F4'  : np.array([0.05038, 0.05184, 0.04133]),\n",
    "               'F8'  : np.array([0.06871, 0.04116, -0.01531]),\n",
    "               'FC3' : np.array([-0.05883, 0.02102, 0.05482]),\n",
    "               'FCz' : np.array([0.00057, 0.02463, 0.08763]),\n",
    "               'FC4' : np.array([0.06029, 0.02116, 0.05558]), \n",
    "               'T7'  : np.array([-0.08336, -0.01652, -0.01265]), \n",
    "               'C3'  : np.array([-0.06557, -0.01325, 0.06498]),\n",
    "               'Cz'  : np.array([0.000023, -0.01128, 0.09981]),\n",
    "               'C4'  : np.array([0.06650, -0.01280, 0.06511]),\n",
    "               'T8'  : np.array([0.08444, -0.01665, -0.01179]), \n",
    "               'CP3' : np.array([-0.06551, -0.04848, 0.06857]),\n",
    "               'CPz' : np.array([-0.0042, -0.04877, 0.09837]), \n",
    "               'CP4' : np.array([0.06503, -0.04835, 0.06857]), \n",
    "               'P7'  : np.array([-0.07146, -0.07517, -0.00370]), \n",
    "               'P3'  : np.array([-0.05507, -0.08011, 0.05944]), \n",
    "               'Pz'  : np.array([-0.00087, -0.08223, 0.08243]),\n",
    "               'P4'  : np.array([0.05351, -0.08013, 0.05940]), \n",
    "               'P8'  : np.array([0.07110, -0.07517, -0.00369]), \n",
    "               'O1'  : np.array([-0.02898, -0.11452, 0.00967]),  \n",
    "               'Oz'  : np.array([-0.00141, -0.11779, 0.01584]),\n",
    "               'O2'  : np.array([0.02689, -0.11468, 0.00945])\n",
    "              }\n",
    "\n",
    "# channel groupings (left/mid/right)\n",
    "l_frontal = ['F3', 'FC3']\n",
    "m_frontal = ['Fz', 'FCz']\n",
    "r_frontal = ['F4', 'FC4']\n",
    "l_central = ['C3', 'CP3']\n",
    "m_central = ['Cz', 'CPz']\n",
    "r_central = ['C4', 'CP4']\n",
    "l_posterior = ['P3', 'O1'] \n",
    "m_posterior = ['Pz', 'Oz'] \n",
    "r_posterior = ['P4', 'O2'] \n",
    "channel_groups = {\n",
    "    'l_frontal': l_frontal,\n",
    "    'm_frontal': m_frontal,\n",
    "    'r_frontal': r_frontal,\n",
    "    'l_central': l_central,\n",
    "    'm_central': m_central,\n",
    "    'r_central': r_central,\n",
    "    'l_posterior': l_posterior,\n",
    "    'm_posterior': m_posterior,\n",
    "    'r_posterior': r_posterior\n",
    "}\n",
    "all_channels = l_frontal + m_frontal + r_frontal + l_central + m_central + r_central + l_posterior + m_posterior + r_posterior\n",
    "\n",
    "# define (5) frequencies of interest for TFR per frequency band\n",
    "delta = np.array([1, 1.5, 2, 2.5, 3]) # starting at one because of high-pass filter\n",
    "theta = np.array([4, 4.75, 5.5, 6.25, 7])\n",
    "alpha = np.array([8, 9, 10, 11, 12])\n",
    "beta = np.array([13, 17.25, 21.5, 25.75, 30])\n",
    "gamma = np.array([42, 54, 66, 78, 90]) \n",
    "bands = {'delta': delta, 'theta': theta, 'alpha': alpha, 'beta': beta, 'gamma': gamma}\n",
    "all_freqs = np.concatenate([delta, theta, alpha, beta, gamma])\n",
    "\n",
    "## Create montage\n",
    "montage = mne.channels.make_dig_montage(ch_pos = dict_ch_pos_array, coord_frame = 'head')\n",
    "\n",
    "# Create info object for MNE\n",
    "info = mne.create_info(ch_names=ch_names, ch_types=ch_types, sfreq=500)\n",
    "info.set_montage(montage=montage, on_missing= 'raise')\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction and storing in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 2/3 files processed.(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "(12,)\n",
      "Progress: 3/3 files processed.\n",
      "\n",
      "Missing diagnoses in EO instances: 0\n",
      "Missing diagnoses in EC instances: 0\n",
      "Missing diagnoses in ratio instances: 0\n",
      "\n",
      "df_features.shape = (24, 680)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>epoch</th>\n",
       "      <th>EO_l_frontal_delta_std</th>\n",
       "      <th>EO_l_frontal_delta_mean</th>\n",
       "      <th>EO_l_frontal_delta_median</th>\n",
       "      <th>EO_l_frontal_delta_skew</th>\n",
       "      <th>EO_l_frontal_delta_kurt</th>\n",
       "      <th>...</th>\n",
       "      <th>ratio_r_posterior_beta_std</th>\n",
       "      <th>ratio_r_posterior_beta_mean</th>\n",
       "      <th>ratio_r_posterior_beta_median</th>\n",
       "      <th>ratio_r_posterior_beta_skew</th>\n",
       "      <th>ratio_r_posterior_beta_kurt</th>\n",
       "      <th>ratio_r_posterior_gamma_std</th>\n",
       "      <th>ratio_r_posterior_gamma_mean</th>\n",
       "      <th>ratio_r_posterior_gamma_median</th>\n",
       "      <th>ratio_r_posterior_gamma_skew</th>\n",
       "      <th>ratio_r_posterior_gamma_kurt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-87966293</td>\n",
       "      <td>65.59</td>\n",
       "      <td>1</td>\n",
       "      <td>SMC</td>\n",
       "      <td>2</td>\n",
       "      <td>0.081658</td>\n",
       "      <td>0.088575</td>\n",
       "      <td>0.088575</td>\n",
       "      <td>1.604179</td>\n",
       "      <td>2.548321</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sub-87966337</td>\n",
       "      <td>57.57</td>\n",
       "      <td>1</td>\n",
       "      <td>SMC</td>\n",
       "      <td>5</td>\n",
       "      <td>0.054678</td>\n",
       "      <td>0.078729</td>\n",
       "      <td>0.078729</td>\n",
       "      <td>1.132516</td>\n",
       "      <td>1.018603</td>\n",
       "      <td>...</td>\n",
       "      <td>1.929829</td>\n",
       "      <td>1.62732</td>\n",
       "      <td>1.133237</td>\n",
       "      <td>8.027325</td>\n",
       "      <td>92.918828</td>\n",
       "      <td>2.508351</td>\n",
       "      <td>1.165224</td>\n",
       "      <td>0.619387</td>\n",
       "      <td>6.262601</td>\n",
       "      <td>41.696742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sub-87966293</td>\n",
       "      <td>65.59</td>\n",
       "      <td>1</td>\n",
       "      <td>SMC</td>\n",
       "      <td>7</td>\n",
       "      <td>0.172679</td>\n",
       "      <td>0.115376</td>\n",
       "      <td>0.115376</td>\n",
       "      <td>3.493359</td>\n",
       "      <td>13.930293</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 680 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ID    age  gender diagnosis  epoch  EO_l_frontal_delta_std  \\\n",
       "1   sub-87966293  65.59       1       SMC      2                0.081658   \n",
       "16  sub-87966337  57.57       1       SMC      5                0.054678   \n",
       "6   sub-87966293  65.59       1       SMC      7                0.172679   \n",
       "\n",
       "    EO_l_frontal_delta_mean  EO_l_frontal_delta_median  \\\n",
       "1                  0.088575                   0.088575   \n",
       "16                 0.078729                   0.078729   \n",
       "6                  0.115376                   0.115376   \n",
       "\n",
       "    EO_l_frontal_delta_skew  EO_l_frontal_delta_kurt  ...  \\\n",
       "1                  1.604179                 2.548321  ...   \n",
       "16                 1.132516                 1.018603  ...   \n",
       "6                  3.493359                13.930293  ...   \n",
       "\n",
       "    ratio_r_posterior_beta_std  ratio_r_posterior_beta_mean  \\\n",
       "1                          NaN                          NaN   \n",
       "16                    1.929829                      1.62732   \n",
       "6                          NaN                          NaN   \n",
       "\n",
       "    ratio_r_posterior_beta_median  ratio_r_posterior_beta_skew  \\\n",
       "1                             NaN                          NaN   \n",
       "16                       1.133237                     8.027325   \n",
       "6                             NaN                          NaN   \n",
       "\n",
       "    ratio_r_posterior_beta_kurt  ratio_r_posterior_gamma_std  \\\n",
       "1                           NaN                          NaN   \n",
       "16                    92.918828                     2.508351   \n",
       "6                           NaN                          NaN   \n",
       "\n",
       "    ratio_r_posterior_gamma_mean  ratio_r_posterior_gamma_median  \\\n",
       "1                            NaN                             NaN   \n",
       "16                      1.165224                        0.619387   \n",
       "6                            NaN                             NaN   \n",
       "\n",
       "    ratio_r_posterior_gamma_skew  ratio_r_posterior_gamma_kurt  \n",
       "1                            NaN                           NaN  \n",
       "16                      6.262601                     41.696742  \n",
       "6                            NaN                           NaN  \n",
       "\n",
       "[3 rows x 680 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import scipy\n",
    "# calculate variance in power per freq band and per channel group for each file and store in dataframe\n",
    "eeg_dir = \"D:\\Documents\\RU\\Master_Neurobiology\\Internship_jaar_2\\Project\\TD-BRAIN\\TDBRAIN-dataset-derivatives\\derivatives\\preprocessed\"\n",
    "\n",
    "#exlude_dirs = ['preprocessed', 'results_manuscript', 'adhd_sample'] # exclude these directories\n",
    "sample_ids = df_participants['participants_ID'].tolist() # list of participants to include\n",
    "# sample_ids = ['sub-87966293', 'sub-87966337']\n",
    "\n",
    "df_ec_features = pd.DataFrame() # create empty dataframe to store EC features\n",
    "df_eo_features = pd.DataFrame() # create empty dataframe to store EO features\n",
    "df_ratio_features = pd.DataFrame() # create empty dataframe to store ratio features\n",
    "\n",
    "# counter for progress\n",
    "count = 1\n",
    "if count == 1:\n",
    "    total_files = 0\n",
    "    for _, dirs, files in os.walk(eeg_dir):\n",
    "        #dirs[:] = [d for d in dirs if d not in exlude_dirs] # exclude directories\n",
    "        total_files += len([file for file in files if any(sample_id in file for sample_id in sample_ids) and '.npy' in file and 'ses-1' in file and 'BAD' not in file])\n",
    "\n",
    "processed_IDs = [] # list to keep track of processed participants for ratio calculation\n",
    "for subdir, dirs, files in os.walk(eeg_dir): # iterate through all files\n",
    "    #dirs[:] = [d for d in dirs if d not in exlude_dirs] # exclude directories\n",
    "    for file in files:\n",
    "        if any(sample_id in file for sample_id in sample_ids): # filter participants to include\n",
    "            if 'ses-1' in file and '.npy' in file and 'BAD' not in file: # filter first session, .npy files, and non-bad files\n",
    "                filepath = os.path.join(subdir, file) # path to eeg file\n",
    "\n",
    "                # needs specific info object, because has one less channel\n",
    "                info = mne.create_info(ch_names=ch_names[:32], ch_types=ch_types[:32], sfreq=500)\n",
    "                info.set_montage(montage=montage, on_missing= 'raise')\n",
    "\n",
    "                preprocessed_eeg = np.load(filepath, allow_pickle = True)\n",
    "                raw = mne.io.RawArray(np.squeeze(preprocessed_eeg['data']), info)\n",
    "\n",
    "                # epoch the data\n",
    "                epochs = mne.make_fixed_length_epochs(raw, duration = 9.95, overlap = 0)\n",
    "\n",
    "                if 'EC' in file:\n",
    "                    cond = 'EC'\n",
    "                if 'EO' in file:\n",
    "                    cond = 'EO'\n",
    "\n",
    "                # determine age, gender, and diagnosis of participant corresponding to file\n",
    "                age = df_participants.loc[df_participants['participants_ID'] == file.split('_')[0], 'age'].values[0]\n",
    "                gender = df_participants.loc[df_participants['participants_ID'] == file.split('_')[0], 'gender'].values[0]\n",
    "                diagnosis = df_participants.loc[df_participants['participants_ID'] == file.split('_')[0], 'diagnosis'].values[0]\n",
    "                \n",
    "\n",
    "                # add data to empty dictionary as a list with the same length as the number of epochs\n",
    "                feature_dict = {}\n",
    "                feature_dict['ID'] = [file.split('_')[0]] * epochs.get_data().shape[0]\n",
    "                feature_dict['age'] = [age] * epochs.get_data().shape[0]\n",
    "                feature_dict['gender'] = [gender] * epochs.get_data().shape[0]\n",
    "                feature_dict['diagnosis'] = [diagnosis] * epochs.get_data().shape[0]\n",
    "                feature_dict['epoch'] = list(range(1, epochs.get_data().shape[0] + 1))\n",
    "\n",
    "                \n",
    "                # calculate TFR for all frequencies in freq bands and all channels in channel groups\n",
    "                tfr_mt = tfr_multitaper(\n",
    "                            epochs,\n",
    "                            freqs=all_freqs,\n",
    "                            n_cycles=(all_freqs / 2),\n",
    "                            time_bandwidth=4,\n",
    "                            use_fft=True,\n",
    "                            return_itc=False,\n",
    "                            average=False,\n",
    "                            decim=8, # decim reduces sampling rate of the tf decomposition by the defined factor\n",
    "                            n_jobs=-1,\n",
    "                            picks=all_channels)\n",
    "                \n",
    "                # TFR normalization with the total average power per frequency\n",
    "                tfr_mt_data = tfr_mt.data # shape [n_epochs, n_channels, n_freqs, n_times]\n",
    "                tfr_mt_avg_freq = np.mean(tfr_mt_data, axis = 3) # average power over time per freq = shape [n_epochs, n_channels, n_freqs]\n",
    "                total_tfr_mt_avg_freq = np.sum(tfr_mt_avg_freq, axis = 2) # sum avg power over freqs = shape [n_epochs, n_channels]\n",
    "                tfr_mt_norm = tfr_mt_data / total_tfr_mt_avg_freq[:, :, np.newaxis, np.newaxis] # normalize by dividing the signal by the sum of avg power over freqs\n",
    "                tfr_mt.data = tfr_mt_norm # store normalized data in tfr object\n",
    "\n",
    "                if 'EC' in file:\n",
    "                    EC_TFR_signal = tfr_mt\n",
    "                if 'EO' in file:\n",
    "                    EO_TFR_signal = tfr_mt\n",
    "                \n",
    "                for group in channel_groups:\n",
    "                    # select channels of interest\n",
    "                    tfr_mt_group = tfr_mt.copy().pick(channel_groups[group]).data # shape [n_epochs, n_channels, n_freqs, n_times]\n",
    "                    for band in bands:\n",
    "\n",
    "                        # select frequencies of interest\n",
    "                        start_index = np.where(tfr_mt.freqs == bands[band][0])[0][0]\n",
    "                        end_index = np.where(tfr_mt.freqs == bands[band][-1])[0][0]\n",
    "                        tfr_mt_band_group = tfr_mt_group[:, :, start_index:end_index, :] # shape [n_epochs, n_channels, n_freqs, n_times]\n",
    "\n",
    "                        # # average signal over channels and frequencies to get one signal per channel group and frequency band\n",
    "                        tfr_mt_avg = np.mean(tfr_mt_band_group, axis = (1, 2)) # average over channels and frequencies = shape [n_epochs, n_times]\n",
    "\n",
    "                        # compute standard deviation in spectral spower per epoch per channel group\n",
    "                        tfr_mt_std = np.std(tfr_mt_avg, axis=1) # calculate stdev over time = shape [n_epochs]\n",
    "                        # compute average spectral power per epoch per channel group\n",
    "                        tfr_mt_mean = np.mean(tfr_mt_avg, axis=1) # calculate mean over time = shape [n_epochs]\n",
    "                        # compute median spectral power per epoch per channel group\n",
    "                        tfr_mt_mean_median = np.median(tfr_mt_avg, axis=1) # calculate median over time = shape [n_epochs]\n",
    "                        # compute skewness of spectral power per epoch per channel group\n",
    "                        tfr_mt_skew = scipy.stats.skew(tfr_mt_avg, axis=1) # calculate skew over time = shape [n_epochs]\n",
    "                        # compute kurtosis of spectral power per epoch per channel group\n",
    "                        tfr_mt_kurt = scipy.stats.kurtosis(tfr_mt_avg, axis=1) # calculate kurt over time = shape [n_epochs]\n",
    "\n",
    "                        # add to dictionary\n",
    "                        feature_dict[f'{cond}_{group}_{band}_std'] = tfr_mt_std # shape [n_epochs]\n",
    "                        feature_dict[f'{cond}_{group}_{band}_mean'] = tfr_mt_mean # shape [n_epochs]\n",
    "                        feature_dict[f'{cond}_{group}_{band}_median'] = tfr_mt_mean # shape [n_epochs]\n",
    "                        feature_dict[f'{cond}_{group}_{band}_skew'] = tfr_mt_skew # shape [n_epochs]\n",
    "                        feature_dict[f'{cond}_{group}_{band}_kurt'] = tfr_mt_kurt # shape [n_epochs]\n",
    "\n",
    "                # If both EC and EO have been processed from the same participant, calculate ratio features, this only works if you only select 1 session per participant\n",
    "                if file.split('_')[0] in processed_IDs:\n",
    "                    ratio_feature_dict = {}\n",
    "                    ratio_feature_dict['ID'] = feature_dict['ID']\n",
    "                    ratio_feature_dict['age'] = feature_dict['age']\n",
    "                    ratio_feature_dict['gender'] = feature_dict['gender']\n",
    "                    ratio_feature_dict['diagnosis'] = feature_dict['diagnosis']\n",
    "                    ratio_feature_dict['epoch'] = feature_dict['epoch']\n",
    "\n",
    "                    # Check if the number of epochs of both arrays are the same\n",
    "                    if EC_TFR_signal.data.shape[0] != EO_TFR_signal.data.shape[0]:\n",
    "                        # If not, find the minimum size\n",
    "                        min_size = min(EC_TFR_signal.data.shape[0], EO_TFR_signal.data.shape[0])\n",
    "\n",
    "                        # Resize the arrays to the minimum size\n",
    "                        EC_TFR_signal.data = EC_TFR_signal.data[:min_size]\n",
    "                        EO_TFR_signal.data = EO_TFR_signal.data[:min_size]\n",
    "                    # calculate ratio of EC and EO signals\n",
    "                    ratio_TFR_signal = EC_TFR_signal.copy() # copy info containing channels and frequencies from EC TFR object to new TFR object for the ratio features\n",
    "                    ratio_TFR_signal.data = np.divide(EC_TFR_signal.data, EO_TFR_signal.data) # shape [n_epochs, n_channels, n_freqs, n_times]\n",
    "                    \n",
    "                    for group in channel_groups:\n",
    "                        # select channels of interest\n",
    "                        tfr_mt_group = ratio_TFR_signal.copy().pick(channel_groups[group]).data # shape [n_epochs, n_channels, n_freqs, n_times]\n",
    "                        for band in bands:\n",
    "\n",
    "                            # select frequencies of interest\n",
    "                            start_index = np.where(tfr_mt.freqs == bands[band][0])[0][0]\n",
    "                            end_index = np.where(tfr_mt.freqs == bands[band][-1])[0][0]\n",
    "                            tfr_mt_band_group = tfr_mt_group[:, :, start_index:end_index, :] # shape [n_epochs, n_channels, n_freqs, n_times]\n",
    "\n",
    "                            # # average signal over channels and frequencies to get one signal per channel group and frequency band\n",
    "                            tfr_mt_avg = np.mean(tfr_mt_band_group, axis = (1, 2)) # average over channels and frequencies = shape [n_epochs, n_times]\n",
    "\n",
    "                            ratio_feature_dict[f'ratio_{group}_{band}_std'] = np.std(tfr_mt_avg, axis=1) # calculate stdev over time = shape [n_epochs]\n",
    "                            ratio_feature_dict[f'ratio_{group}_{band}_mean'] = np.mean(tfr_mt_avg, axis=1) # calculate mean over time = shape [n_epochs]\n",
    "                            ratio_feature_dict[f'ratio_{group}_{band}_median'] = np.median(tfr_mt_avg, axis=1) # calculate median over time = shape [n_epochs]\n",
    "                            ratio_feature_dict[f'ratio_{group}_{band}_skew'] = scipy.stats.skew(tfr_mt_avg, axis=1) # calculate skew over time = shape [n_epochs]\n",
    "                            ratio_feature_dict[f'ratio_{group}_{band}_kurt'] = scipy.stats.kurtosis(tfr_mt_avg, axis=1) # calculate kurt over time = shape [n_epochs]\n",
    "                    \n",
    "                    df_ratio_features = pd.concat([df_ratio_features, pd.DataFrame(ratio_feature_dict)], ignore_index = True)\n",
    "                    \n",
    "                # add to dataframe\n",
    "                if cond == 'EC':\n",
    "                    df_ec_features = pd.concat([df_ec_features, pd.DataFrame(feature_dict)], ignore_index = True)\n",
    "                if cond == 'EO':\n",
    "                    df_eo_features = pd.concat([df_eo_features, pd.DataFrame(feature_dict)], ignore_index = True)\n",
    "\n",
    "                processed_IDs.append(file.split('_')[0]) # add participant to list of processed participants\n",
    "\n",
    "                print(f'\\rProgress: {count}/{total_files} files processed.', end = '')\n",
    "                count += 1\n",
    "\n",
    "# merge EO and EC dataframes\n",
    "print('\\n')\n",
    "print('Missing diagnoses in EO instances:', df_eo_features['diagnosis'].isnull().sum()) # sanity check\n",
    "print('Missing diagnoses in EC instances:', df_ec_features['diagnosis'].isnull().sum()) # sanity check\n",
    "print('Missing diagnoses in ratio instances:', df_ratio_features['diagnosis'].isnull().sum()) # sanity check\n",
    "# merge EO, EC and ratio dataframes\n",
    "df_features = pd.merge(df_eo_features, pd.merge(df_ec_features.drop(columns=['age', 'gender']), df_ratio_features.drop(columns=['age', 'gender']),  how='outer', on=['ID', 'epoch', 'diagnosis']),  how='outer', on=['ID', 'epoch', 'diagnosis'])\n",
    "del df_ec_features, df_eo_features, df_ratio_features # remove dataframes to free up memory                \n",
    "print(f'\\n{df_features.shape = }')\n",
    "df_features.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of each feature as a histogram\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "numeric_cols = [col for col in df_features.columns if 'EC' in col or 'EO' in col or 'ratio' in col]\n",
    "# Create a PdfPages object\n",
    "with PdfPages('test_standardized_feature_distributions.pdf') as pdf:\n",
    "    # Iterate over numeric columns\n",
    "    for i in range(0, len(numeric_cols), 5):\n",
    "        # Create a new figure for each set of 5 features\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        \n",
    "        for j in range(5):\n",
    "            if i+j < len(numeric_cols):\n",
    "                plt.subplot(5, 1, j+1)\n",
    "                sns.histplot(df_features[numeric_cols[i+j]], kde=False)\n",
    "                plt.title(numeric_cols[i+j])\n",
    "        \n",
    "        # Tight layout often produces nice results\n",
    "        # but requires the title to be spaced accordingly\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.88)\n",
    "        \n",
    "        # Save the current figure to the pdf\n",
    "        pdf.savefig()\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                                 0\n",
       "age                                0\n",
       "gender                             0\n",
       "diagnosis                          0\n",
       "epoch                              0\n",
       "                                  ..\n",
       "ratio_r_posterior_gamma_std       12\n",
       "ratio_r_posterior_gamma_mean      12\n",
       "ratio_r_posterior_gamma_median    12\n",
       "ratio_r_posterior_gamma_skew      12\n",
       "ratio_r_posterior_gamma_kurt      12\n",
       "Length: 680, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.to_pickle('D:\\Documents\\RU\\Master_Neurobiology\\Internship_jaar_2\\Project\\TD-BRAIN\\TD-BRAIN_extracted_features/df_stat_features.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mne",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
